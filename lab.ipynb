{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c20cd51d",
   "metadata": {},
   "source": [
    "# Integrantes\n",
    "\n",
    "Mauricio Lemus - 22461\n",
    "\n",
    "Hugo Rivas - 22500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af41c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Fijar semilla para reproducibilidad\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48488e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Transformaciones: a tensor y normalización (media=0.1307, std=0.3081 en MNIST)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Descarga y carga\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ff0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, layer_sizes, activation_fn):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for in_dim, out_dim in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            layers.append(nn.Linear(in_dim, out_dim))\n",
    "            # no añadimos activación después de la última capa\n",
    "            if out_dim != layer_sizes[-1]:\n",
    "                layers.append(activation_fn())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # aplanar 28×28 → 784\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fb40b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "    return 100. * correct / len(test_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08459503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración A: Test Accuracy = 96.27%\n",
      "Configuración B: Test Accuracy = 76.20%\n",
      "Configuración C: Test Accuracy = 94.51%\n"
     ]
    }
   ],
   "source": [
    "configs = {\n",
    "    'A': {'layers':[784,128,10],    'act':nn.ReLU,    'lr':0.01,  'batch':64,  'epochs':10},\n",
    "    'B': {'layers':[784,256,128,10],'act':nn.Sigmoid, 'lr':0.005, 'batch':128, 'epochs':15},\n",
    "    'C': {'layers':[784,512,256,128,10],'act':nn.ReLU,'lr':0.001,'batch':32, 'epochs':20}\n",
    "}\n",
    "results = {}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for name, cfg in configs.items():\n",
    "    # DataLoaders según batch_size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=cfg['batch'], shuffle=True)\n",
    "    test_loader  = DataLoader(test_dataset,  batch_size=cfg['batch'], shuffle=False)\n",
    "\n",
    "    # Modelo, optimizador\n",
    "    model = MLP(cfg['layers'], cfg['act']).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=cfg['lr'])\n",
    "\n",
    "    # Entrenamiento\n",
    "    for ep in range(1, cfg['epochs']+1):\n",
    "        train(model, device, train_loader, optimizer, ep)\n",
    "\n",
    "    # Evaluación\n",
    "    acc = test(model, device, test_loader)\n",
    "    results[name] = acc\n",
    "    print(f\"Configuración {name}: Test Accuracy = {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a5dcd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=0.0001, batch=32 → acc=85.79%\n",
      "lr=0.0001, batch=64 → acc=81.35%\n",
      "lr=0.0001, batch=128 → acc=71.57%\n",
      "lr=0.001, batch=32 → acc=92.50%\n",
      "lr=0.001, batch=64 → acc=91.16%\n",
      "lr=0.001, batch=128 → acc=89.64%\n",
      "lr=0.005, batch=32 → acc=96.21%\n",
      "lr=0.005, batch=64 → acc=94.71%\n",
      "lr=0.005, batch=128 → acc=93.27%\n",
      "lr=0.01, batch=32 → acc=97.19%\n",
      "lr=0.01, batch=64 → acc=96.17%\n",
      "lr=0.01, batch=128 → acc=94.98%\n",
      "lr=0.1, batch=32 → acc=98.05%\n",
      "lr=0.1, batch=64 → acc=97.19%\n",
      "lr=0.1, batch=128 → acc=98.03%\n",
      "Mejor combinación: {'lr': 0.1, 'batch': 32, 'acc': 98.05}\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "grid = {\n",
    "    'lr': [0.0001,0.001, 0.005, 0.01,0.1],\n",
    "    'batch': [32, 64, 128,]\n",
    "}\n",
    "best = {'acc': 0}\n",
    "for lr, batch in product(grid['lr'], grid['batch']):\n",
    "    # DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
    "    test_loader  = DataLoader(test_dataset,  batch_size=batch, shuffle=False)\n",
    "\n",
    "    # Modelo\n",
    "    model = MLP(configs['A']['layers'], configs['A']['act']).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    # Entrenamiento breve (p. ej. 5 épocas)\n",
    "    for ep in range(1, 11):\n",
    "        train(model, device, train_loader, optimizer, ep)\n",
    "\n",
    "    acc = test(model, device, test_loader)\n",
    "    print(f\"lr={lr}, batch={batch} → acc={acc:.2f}%\")\n",
    "    if acc > best['acc']:\n",
    "        best = {'lr':lr, 'batch':batch, 'acc':acc}\n",
    "\n",
    "print(\"Mejor combinación:\", best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5292757a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Red  Accuracy (%)\n",
      "0  A_tuned         98.05\n",
      "1        A         96.27\n",
      "2        C         94.51\n",
      "3        B         76.20\n"
     ]
    }
   ],
   "source": [
    "# Agregar la mejor variante del grid search como \"A_tuned\"\n",
    "results['A_tuned'] = best['acc']\n",
    "df = pd.DataFrame([\n",
    "    {'Red': k, 'Accuracy (%)': v} for k, v in results.items()\n",
    "]).sort_values('Accuracy (%)', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a7d25a",
   "metadata": {},
   "source": [
    "### Evaluación y Conclusiones\n",
    "\n",
    "\n",
    "**¿Qué hiperparámetros influyeron más en el rendimiento del modelo?**\n",
    "\n",
    "Los hiperparámetros que más influyeron en la mejora del rendimiento fueron:\n",
    "\n",
    "- **Learning rate**: Tuvo un impacto significativo, ya que un valor muy alto llevó a inestabilidad y uno muy bajo ralentizó el aprendizaje. Encontrar un valor intermedio como `0.005` o `0.001` permitió un entrenamiento más efectivo.\n",
    "- **Número de capas ocultas y neuronas**: Las arquitecturas más profundas (como la red C) mostraron mejor capacidad de generalización, aunque con más riesgo de sobreajuste.\n",
    "- **Batch size**: Influyó en la estabilidad y rapidez del entrenamiento. Tamaños pequeños como 32 proporcionaron mayor precisión en el gradiente, mientras que tamaños medianos como 64 ofrecieron un buen balance entre rendimiento y velocidad.\n",
    "- **Función de activación**: ReLU mostró mejor rendimiento general comparado con Sigmoid, debido a su comportamiento no saturante y mejor propagación del gradiente.\n",
    "\n",
    "El ajuste de hiperparámetros como la tasa de aprendizaje y la arquitectura de la red fue clave para mejorar el rendimiento. El grid search permitió encontrar una configuración óptima para la red A.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
